{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the data available in the dataset folder. \n",
    "\n",
    "Try to answer the questions using python.\n",
    "\n",
    "Be clear and get straight to the point in your answers.\n",
    "\n",
    "Good job!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to clean/aggregate the data from grid_weather_data.sql in order to avoid NULL (or NaN) values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step on the process of cleaning the dataset was to understand how much data was missing and if there was any clear pattern on why it's missing.\n",
    "\n",
    "For that, the dataset was loaded into a pandas dataframe and using its built-in methods to analyze the amount of missing rows in each column and its percentage when compared to the total.\n",
    "\n",
    "- Total of missing values per column:\n",
    "\n",
    "```py\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "| **Column**            | **Missing Values** |\n",
    "|-----------------------|--------------------|\n",
    "| cod_city              | 0                  |\n",
    "| date                  | 0                  |\n",
    "| hour                  | 0                  |\n",
    "| precipitation         | 76698              |\n",
    "| dry_bulb_temperature  | 5966               |\n",
    "| wet_bulb_temperature  | 16473              |\n",
    "| high_temperature      | 79166              |\n",
    "| low_temperature       | 78710              |\n",
    "| relative_humidity     | 9648               |\n",
    "| relative_humidity_avg | 81742              |\n",
    "| pressure              | 19480              |\n",
    "| sea_pressure          | 69868              |\n",
    "| wind_direction        | 11324              |\n",
    "| wind_speed_avg        | 82790              |\n",
    "| cloud_cover           | 81082              |\n",
    "| evaporation           | 10299              |\n",
    "\n",
    "\n",
    "- Percentage of missing values per column:\n",
    "```py\n",
    "for col in df:\n",
    "    if df[col].isnull().mean()>0:\n",
    "        print(col, round(df[col].isnull().mean(),4))\n",
    "```\n",
    "| **Column**            | **Missing Values (%)** |\n",
    "|-----------------------|------------------------|\n",
    "| precipitation         | 0.6647                 |\n",
    "| dry_bulb_temperature  | 0.0517                 |\n",
    "| wet_bulb_temperature  | 0.1428                 |\n",
    "| high_temperature      | 0.6861                 |\n",
    "| low_temperature       | 0.6821                 |\n",
    "| relative_humidity     | 0.0836                 |\n",
    "| relative_humidity_avg | 0.7084                 |\n",
    "| pressure              | 0.1688                 |\n",
    "| sea_pressure          | 0.6055                 |\n",
    "| wind_direction        | 0.0981                 |\n",
    "| wind_speed_avg        | 0.7175                 |\n",
    "| cloud_cover           | 0.7027                 |\n",
    "| evaporation           | 0.0893                 |\n",
    "\n",
    "Based on the data, it can be seem that there's a relevant amount of data missing that does not seem to follow any specific pattern. Given that, the missing values will be replaced by using the median of the numerical column following the code below.\n",
    "\n",
    "```py\n",
    "for col in df_numerical:\n",
    "    col_median = df_numerical[col].median()\n",
    "    df_numerical[col].fillna(col_median, inplace=True)\n",
    "```\n",
    "\n",
    "The clean dataset is saved on a csv file called \"clean_dataset.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the precipitation mean of each city throughout 2002?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following query below in the postgres database it's possible to get the mean precipitation of each city\n",
    "in the mentioned year.\n",
    "\n",
    "```sql\n",
    "SELECT cod_city, avg(precipitation) \n",
    "FROM weather.grid_weather_data gwd \n",
    "WHERE date BETWEEN '2002-01-01' AND '2002-12-31'\n",
    "GROUP BY cod_city;\n",
    "```\n",
    "\n",
    "Using the cod_city from the database with the name of the city from the json file the following table is created:\n",
    "\n",
    "| cod_city | city_name      | mean_precipitation |\n",
    "| -------- | ------------- | ------------------ |\n",
    "| 59999    | ALTO PARNAIBA | 3.932328767123288  |\n",
    "| 60020    | BARREIRAS     | 2.603013698630137  |\n",
    "| 60046    | CANARANA      | 4.619607843137253  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features have some correlation?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coeffients (p) were calculated using a method from the pandas dataframe called \"corr\". This method saves the results on a numpy array. Since the visualization of the array is unpratical it was plotted as a heatmap using matplotlib and seaborn.\n",
    "\n",
    "```py\n",
    "correlation = df_numerical.corr()\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.title('Correlation Heatmap')\n",
    "ax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \n",
    "plt.show()\n",
    "```\n",
    "The figure is shown below:\n",
    "\n",
    "![Heatmap](correlation_heatmap.png)\n",
    "\n",
    "Given that the correlation range is expressed from -1(negative perfect correlation) to +1(perfect correlation) with 0 being no correlation. It's possible to determine that these features are correlated:\n",
    "\n",
    "- relative_humidity and dry_bulb_temperature (moderate/strong negative)\n",
    "- Dry_bulb_temperature and wet_bulb_temperature (weak positive)\n",
    "- Low_temperature and wet_bulb_temperature (weak positive)\n",
    "- Wind_speed_avg and wet_bulb_temperature (weak positive)\n",
    "- Evaporarion and wet_bulb_temperature (weak positive)\n",
    "- High_temperature and relative_umidity_avg (moderate positive)\n",
    "- High_temperature and wind_speed_avg (moderate negative)\n",
    "- Cloud_cover and High_temperature (moderate positive)\n",
    "- Wind_speed_avg and cloud_cover (weak/moderate positive)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create time-series plots using python to show the correlations found in the previous question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the answer for the question 3 with the correlation heatmap. Two different plots will be made, one considering a strong negative correlation (relative_humidity and dry_bulb_temperature) and a moderate positive one (cloud_cover and high temperature).\n",
    "\n",
    "The first plot shows that these two features usually have oposite behaviors, when one rises the other falls, working both ways:\n",
    "\n",
    "![Negative Correlation](negative_correlation.png)\n",
    "\n",
    "The second plot shows the moderate positive correlation, given that the two features have similar behaviours, when one rises the other one rises too, however, being only of moderate strengh the pattern does not happen every time.\n",
    "\n",
    "![Positive Moderate Correlation](moderate_correlation.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an exploratory analysis under the data and present your insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a Rest API using python framework (e.g., django, fastapi, flask, tornado) in order to provide the weather data inside of grid_weather_data.sql and grid_weather.json\n",
    "\n",
    "- Create and use any kind of database to make a CRUD to use it later. \n",
    "\n",
    "- Try to provide a swagger to describe your API's structure.\n",
    "\n",
    "- Try to host it in some cloud platform (e.g., heroku, pythonanywhere), and don't forget to provide the link to access it. Otherwise, prepare modules and run server/database in order to (1) run on some env: pip install requirements.txt; (2) them run server.py: python server.py.\n",
    "\n",
    "- Share below a link to your Rest API code stored in a repository from GitHub."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/gv-public/seedz-tech-interview\n",
    "\n",
    "More info on the README.md file on the repository"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a python script in order to make many requests in parallel to your Rest API that you've created in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO PUT A TIME.SLEEP(10) OR HIGHER\n",
    "\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "# Função para fazer uma requisição à API\n",
    "def fazer_requisicao(url):\n",
    "    response = requests.get(url)\n",
    "    # Você pode adicionar aqui o processamento da resposta da requisição, se necessário\n",
    "    return response.json()\n",
    "\n",
    "# Lista de URLs da API que deseja acessar\n",
    "urls = [\n",
    "    \"https://api.exemplo.com/endpoint1\",\n",
    "    \"https://api.exemplo.com/endpoint2\",\n",
    "    \"https://api.exemplo.com/endpoint3\",\n",
    "    # Adicione mais URLs da API, se necessário\n",
    "]\n",
    "\n",
    "# Criando um executor para executar as requisições em paralelo\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Fazendo as requisições em paralelo e obtendo os resultados\n",
    "    resultados = executor.map(fazer_requisicao, urls)\n",
    "\n",
    "    # Iterando sobre os resultados\n",
    "    for resultado in resultados:\n",
    "        # Processando os resultados das requisições, se necessário\n",
    "        print(resultado)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
